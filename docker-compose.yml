services:
  app:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app/src
      - ./great_expectations:/app/great_expectations
    command: uvicorn src.service.app:app --host 0.0.0.0 --port 8000 --reload
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    env_file:
      - .env

  simulator:
    build: .
    ports:
      - "9090:9090"
    volumes:
      - ./simulator:/app/simulator
    command: uvicorn simulator.replay:app --host 0.0.0.0 --port 9090 --reload
    env_file:
      - .env

  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  airflow-init-user:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: f1-live-ops-airflow
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    command: bash -c "airflow users create -u admin -f admin -l user -r Admin -e admin@example.com -p admin"
    restart: "no"

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: f1-live-ops-airflow
    depends_on:
      - postgres
      - airflow-init-user
    environment:
      - GREAT_EXPECTATIONS_HOME=/opt/airflow/great_expectations
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_SECRET_KEY:-sup3r_s3cr3t_long_random_string}
      - PYTHONPATH=/opt/airflow:/opt/airflow/src:/opt/airflow/feature_repo
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000

    env_file:
      - .env
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
      - ./great_expectations:/opt/airflow/great_expectations
      - ./data:/opt/airflow/data
      - ./feature_repo:/opt/airflow/feature_repo

    ports:
      - "8080:8080"
    command: webserver
    mem_limit: 16g
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: f1-live-ops-airflow
    depends_on:
      - postgres
      - airflow-init-user
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./src:/opt/airflow/src
      - ./great_expectations:/opt/airflow/great_expectations
      - ./data:/opt/airflow/data
      - ./feature_repo:/opt/airflow/feature_repo

    environment:
    - GREAT_EXPECTATIONS_HOME=/opt/airflow/great_expectations
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_SECRET_KEY:-sup3r_s3cr3t_long_random_string}
    - PYTHONPATH=/opt/airflow:/opt/airflow/src:/opt/airflow/feature_repo
    - MLFLOW_TRACKING_URI=http://mlflow-server:5000


    command: scheduler
  
  redis-cache:
    image: redis:7
    ports:
      - "6379:6379"
    volumes:
      - redisdata:/data
    restart: unless-stopped

  mlflow-server:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: mlflow-server
    ports:
      - "5000:5000"
    volumes:
      - mlflow-data:/mlflow
    restart: unless-stopped



volumes:
  postgres-db-volume:
  redisdata:
  mlflow-data: